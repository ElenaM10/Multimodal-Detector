## Audio Spectrogram Architecture for Audio Features

import os
import torchaudio
import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import torch.nn.functional as F

# Paths
audio_folder_path = '/content/Preprocessing/extracted_audio' 
metadata_csv_path = '/content/metadata.csv'  

# Custom Dataset for loading audio files
class AudioDataset(Dataset):
    def __init__(self, csv_file, audio_dir, transform=None):
        self.labels_df = pd.read_csv(csv_file)
        self.audio_dir = audio_dir
        self.transform = transform

    def __len__(self):
        return len(self.labels_df)

    def __getitem__(self, idx):
        # Extract audio filename and label from the metadata
        audio_name = self.labels_df.iloc[idx, 0].replace('.mp4', '.wav').lower()  
        label = 1 if self.labels_df.iloc[idx, 1].lower() == 'fake' else 0  

        try:
            audio_path = os.path.join(self.audio_dir, audio_name)

            if not os.path.exists(audio_path):
                raise FileNotFoundError(f"Audio file {audio_name} not found at {audio_path}")

            # Load the audio file (torchaudio loads it as a waveform)
            waveform, sample_rate = torchaudio.load(audio_path)

            # Convert stereo to mono 
            if waveform.shape[0] > 1:
                waveform = torch.mean(waveform, dim=0, keepdim=True)

            # Apply any transformations
            if self.transform:
                waveform = self.transform(waveform)

            return waveform, label

        except (FileNotFoundError, Exception) as e:
            print(f"Warning: Could not load audio for {audio_name}. Error: {e}")
            # Return a blank audio tensor and default label
            return torch.zeros(1, 16000), 0 

# Custom collate function to handle variable-length audio by padding
def collate_fn(batch):
    # Extract the waveforms and labels from the batch
    waveforms = [item[0] for item in batch]
    labels = [item[1] for item in batch]

    # Find the longest waveform in the batch
    max_length = max([waveform.shape[1] for waveform in waveforms])

    # Pad each waveform to the length of the longest waveform in the batch
    padded_waveforms = [F.pad(waveform, (0, max_length - waveform.shape[1])) for waveform in waveforms]

    # Stack waveforms and labels into tensors
    padded_waveforms = torch.stack(padded_waveforms)
    labels = torch.tensor(labels)

    return padded_waveforms, labels

# Define the path to the CSV file and audio folder
audio_dataset = AudioDataset(csv_file=metadata_csv_path, audio_dir=audio_folder_path)

# Create DataLoader for the audio dataset, with the custom collate function
audio_loader = DataLoader(audio_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)

# Example to test loading the audio files
for i, (waveforms, labels) in enumerate(audio_loader):
    print(f"Batch {i+1}:")
    print(f"Waveforms shape: {waveforms.shape}, Labels: {labels}")
    break  
