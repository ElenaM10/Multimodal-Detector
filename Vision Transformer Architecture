## Vision Transformer Architecture for Video Features

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
import pandas as pd
import cv2 
import timm  
import numpy as np
import matplotlib.pyplot as plt

# 1. Define Custom Dataset using metadata.csv and OpenCV
class LabeledDataset(Dataset):
    def __init__(self, csv_file, img_dir, transform=None, img_ext=".jpg"):
        self.labels_df = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        self.img_ext = img_ext  # Image extension (default: .jpg)

    def __len__(self):
        return len(self.labels_df)

    def __getitem__(self, idx):
        # Extract video name (without .mp4 suffix) and label from metadata
        video_name = self.labels_df.iloc[idx, 0].replace('.mp4', '').lower()  
        label = 1 if self.labels_df.iloc[idx, 1].lower() == 'fake' else 0  

        try:
            all_files = os.listdir(self.img_dir)

            
            # Look for the first file that starts with the video name (ignore case)
            img_name = [
                name for name in all_files
                if name.lower().startswith(video_name) and name.lower().endswith(self.img_ext)
            ]

            if not img_name:
                raise FileNotFoundError(f"No image found for {video_name}")

            print(f"Found matching image: {img_name[0]} in folder")
            full_img_path = os.path.join(self.img_dir, img_name[0])

            # Load image with OpenCV (in BGR format, convert to RGB)
            image = cv2.imread(full_img_path)
            if image is None:
                raise FileNotFoundError(f"Image not loaded properly for {full_img_path}")
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # Convert the image to a PIL-like tensor format (HWC -> CHW)
            image = torch.tensor(image).permute(2, 0, 1).float() / 255.0  # Normalize between 0 and 1

            # Apply transformations
            if self.transform:
                image = self.transform(image)

            return image, label

        except (FileNotFoundError, Exception) as e:
            print(f"Warning: Could not load image for {video_name}, returning a blank image. Error: {e}")
            # Return a black image and a default label
            return torch.zeros((3, 224, 224)), 0

# 2. Define transformations and load dataset
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Paths
metadata_csv_path = '/content/metadata.csv'  
image_folder_path = '/content/Preprocessing/detected_faces/detected_faces'  

# Create dataset and dataloader
train_dataset = LabeledDataset(csv_file=metadata_csv_path, img_dir=image_folder_path, transform=transform, img_ext=".jpg")
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# 3. Define Vision Transformer Model
class DeepfakeDetectionModel(nn.Module):
    def __init__(self, num_classes=2):
        super(DeepfakeDetectionModel, self).__init__()
        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True) 
        self.vit.head = nn.Linear(self.vit.head.in_features, num_classes) 

    def forward(self, x):
        return self.vit(x)

# Initialize model, loss function, and optimizer
model = DeepfakeDetectionModel(num_classes=2) 
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Move model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# 4. Training Loop with Checkpoint Saving and Loss Logging
num_epochs = 100
checkpoint_interval = 10  
checkpoint_dir = './checkpoints'
os.makedirs(checkpoint_dir, exist_ok=True)

# List to store loss values for plotting
losses = []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    batch_count = 0  # To track batch counts

    for i, (images, labels) in enumerate(train_loader, 0):
        if images is None or labels is None:
            continue

        images, labels = images.to(device), labels.to(device)

        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward pass and optimization
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        batch_count += 1

        # Print and store loss for every batch
        print(f"[Epoch {epoch + 1}, Batch {i + 1}] Loss: {loss.item():.3f}")
        losses.append(loss.item()) 

    # Save checkpoint at specified intervals
    if (epoch + 1) % checkpoint_interval == 0:
        checkpoint_path = os.path.join(checkpoint_dir, f"checkpoint_epoch_{epoch + 1}.pth")
        torch.save(model.state_dict(), checkpoint_path)
        print(f"Checkpoint saved: {checkpoint_path}")

# Check if there are losses to plot
if len(losses) > 0:
    # Plot the training loss
    plt.plot(losses)
    plt.title('Training Loss over Batches')
    plt.xlabel('Batch')
    plt.ylabel('Loss')
    plt.show()
else:
    print("No losses to plot.")
